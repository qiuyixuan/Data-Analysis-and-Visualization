{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yixuan Qiu**\n",
    "\n",
    "Spring 2020\n",
    "\n",
    "CS 251: Data Analysis and Visualization\n",
    "\n",
    "Project 6: Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Naive Bayes Classifier\n",
    "\n",
    "After finishing your email preprocessing pipeline, implement the one other supervised learning algorithm we we will use to classify email, **Naive Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Implement Naive Bayes\n",
    "\n",
    "In `naive_bayes.py`, implement the following methods:\n",
    "- Constructor\n",
    "- `train(data, y)`: Train the Naive Bayes classifier so that it records the \"statistics\" of the training set: class priors (i.e. how likely an email is in the training set to be spam or ham?) and the class likelihoods (the probability of a word appearing in each class â€” spam or ham).\n",
    "- `predict(data)`: Combine the class likelihoods and priors to compute the posterior distribution. The predicted class for a test sample is the class that yields the highest posterior probability.\n",
    "- `accuracy(y, y_pred)`: The usual definition :)\n",
    "\n",
    "\n",
    "#### Bayes rule ingredients: Priors and likelihood (`train`)\n",
    "\n",
    "To compute class predictions (probability that a test example belong to either spam or ham classes), we need to evaluate **Bayes Rule**. This means computing the priors and likelihoods based on the training data.\n",
    "\n",
    "**Prior:** $$P_c = \\frac{N_c}{N}$$ where $P_c$ is the prior for class $c$ (spam or ham), $N_c$ is the number of training samples that belong to class $c$ and $N$ is the total number of training samples.\n",
    "\n",
    "**Likelihood:** $$L_{c,w} = \\frac{N_{c,w} + 1}{N_{c} + M}$$ where\n",
    "- $L_{c,w}$ is the likelihood that word $w$ belongs to class $c$ (*i.e. what we are solving for*)\n",
    "- $N_{c,w}$ is the total count of **word $w$** in emails that are only in class $c$ (*either spam or ham*)\n",
    "- $N_{c}$ is the total number of **all words** that appear in emails of the class $c$ (*total number of words in all spam emails or total number of words in all ham emails*)\n",
    "- $M$ is the number of features (*number of top words*).\n",
    "\n",
    "#### Bayes rule ingredients: Posterior (`predict`)\n",
    "\n",
    "To make predictions, we now combine the prior and likelihood to get the posterior:\n",
    "\n",
    "**Posterior:** $$\\text{Post}_{i, c} = Log(P_c) + \\sum_{j \\in J_i}Log(L_{c,j})$$ where\n",
    "- $\\text{Post}_c$ is the posterior for class $c$ for test sample $i$(*i.e. evidence that email $i$ is spam or ham*). What we are solving for.\n",
    "- $Log(P_c)$ is the logarithm of the prior for class $c$ $P_c$.\n",
    "- $j \\in J_i$ (under the sum) indexes the set of words in the current test sample that have nonzero counts (*i.e. which words show up in the current test set email $i$? $j$ is the index of each of these words.*)\n",
    "- $\\sum_{j \\in J_i}Log(L_{c,j})$: we sum over the log-likelihoods ONLY PERTAINING TO CLASS $c$ at word word indices that appear in the current test email $i$ (i.e. indices at which the counts are > 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_bayes_multinomial import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your class priors are: [0.24 0.26 0.25 0.25]\n",
      "and should be          [0.24 0.26 0.25 0.25].\n",
      "Your class likelihoods shape is (4, 6) and should be (4, 6).\n",
      "Your likelihoods are:\n",
      "[[0.15116 0.18497 0.17571 0.1463  0.16813 0.17374]\n",
      " [0.16695 0.17437 0.15742 0.16887 0.15677 0.17562]\n",
      " [0.14116 0.1562  0.19651 0.17046 0.17951 0.15617]\n",
      " [0.18677 0.18231 0.15884 0.12265 0.16755 0.18187]]\n",
      "and should be\n",
      "[[0.15116 0.18497 0.17571 0.1463  0.16813 0.17374]\n",
      " [0.16695 0.17437 0.15742 0.16887 0.15677 0.17562]\n",
      " [0.14116 0.1562  0.19651 0.17046 0.17951 0.15617]\n",
      " [0.18677 0.18231 0.15884 0.12265 0.16755 0.18187]]\n"
     ]
    }
   ],
   "source": [
    "num_test_classes = 4\n",
    "np.random.seed(0)\n",
    "data_test = np.random.random(size=(100, 6))\n",
    "y_test = np.random.randint(low=0, high=num_test_classes, size=(100,))\n",
    "\n",
    "nbc = NaiveBayes(num_classes=num_test_classes)\n",
    "nbc.train(data_test, y_test)\n",
    "\n",
    "print(f'Your class priors are: {nbc.class_priors}\\nand should be          [0.24 0.26 0.25 0.25].')\n",
    "print(f'Your class likelihoods shape is {nbc.class_likelihoods.shape} and should be (4, 6).')\n",
    "print(f'Your likelihoods are:\\n{nbc.class_likelihoods}')\n",
    "\n",
    "\n",
    "test_likelihoods = np.array([[0.15116, 0.18497, 0.17571, 0.1463 , 0.16813, 0.17374],\n",
    "       [0.16695, 0.17437, 0.15742, 0.16887, 0.15677, 0.17562],\n",
    "       [0.14116, 0.1562 , 0.19651, 0.17046, 0.17951, 0.15617],\n",
    "       [0.18677, 0.18231, 0.15884, 0.12265, 0.16755, 0.18187]])\n",
    "print(f'and should be\\n{test_likelihoods}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your predicted classes are [2 2 2 2] and should be [2 2 2 2].\n"
     ]
    }
   ],
   "source": [
    "num_test_classes = 4\n",
    "np.random.seed(0)\n",
    "data_train = np.random.random(size=(100, 10))\n",
    "data_test = np.random.random(size=(4, 10))\n",
    "y_test = np.random.randint(low=0, high=num_test_classes, size=(100,))\n",
    "\n",
    "nbc = NaiveBayes(num_classes=num_test_classes)\n",
    "nbc.train(data_train, y_test)\n",
    "test_y_pred = nbc.predict(data_test)\n",
    "\n",
    "print(f'Your predicted classes are {test_y_pred} and should be [2 2 2 2].')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) Spam filtering\n",
    "\n",
    "Let's start classifying spam email using the Naive Bayes classifier.\n",
    "\n",
    "- Use `np.load` to load in the train/test split that you created last week.\n",
    "- Use your Naive Bayes classifier on the Enron email dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:** What accuracy do you get on the test set with Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 9:**<br>\n",
    "0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/qiuyixuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import email_preprocessor as epp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training and test data into numpy ndarrays using np.load()\n",
    "# (the files you created at the end of the previous notebook)\n",
    "\n",
    "train_data = np.load('data/email_train_x.npy')\n",
    "test_data = np.load('data/email_test_x.npy')\n",
    "y_train = np.load('data/email_train_y.npy')\n",
    "y_test = np.load('data/email_test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct your classifier\n",
    "nb = NaiveBayes(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8902077151335311\n"
     ]
    }
   ],
   "source": [
    "# Train and test your classifier\n",
    "nb.train(train_data, y_train)\n",
    "y_pred = nb.predict(test_data)\n",
    "accuracy = nb.accuracy(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d) Confusion matrix\n",
    "\n",
    "To get a better sense of the errors that the Naive Bayes classifer makes, you will create a confusion matrix. \n",
    "\n",
    "- Implement `confusion_matrix` in `naive_bayes.py`.\n",
    "- Print out a confusion matrix of the spam classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3237  175]\n",
      " [ 565 2763]]\n"
     ]
    }
   ],
   "source": [
    "print(nb.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10:** Interpret the confusion matrix, using the convention that positive detection means spam (*e.g. a false positive means classifying a ham email as spam*). What types of errors are made more frequently by the classifier? What does this mean (*i.e. X (spam/ham) is more likely to be classified than Y (spam/ham) than the other way around*)?\n",
    "\n",
    "**Reminder: Look back at your preprocessing code: which class indices correspond to spam/ham?**\n",
    "\n",
    "**Answer 10:**<br>\n",
    "False positive errors.<br>\n",
    "A ham is more likely to be classified as spam than the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e) Investigate the misclassification errors\n",
    "\n",
    "Numbers are nice, but they may not the best for developing your intuition. Sometimes, you want to see what an misclassification *actually* looks like to build your understanding as you look to improve your algorithm. Here, you will take a false positive and a false negative misclassification and retrieve the actual text of the email so see which emails produced the error.\n",
    "\n",
    "- Determine the index of the **FIRST** false positive and false negative misclassification â€” i.e. 2 indices in total. Remember to use your inds array to figure out the index of the emails BEFORE shuffling happened.\n",
    "- **Section B:** Implement the function `retrieve_emails` in `email_preprocessor.py` to return the string of the raw email at the error indices. (**Sections A/C** have been supplied with this function on Classroom.)\n",
    "- Call your function to print out the two emails that produced misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11:** What do you think it is about each email that resulted in it being misclassified?\n",
    "\n",
    "**Answer 11:**<br>\n",
    "The first email is long, so it has a higher chance to hit the words common in spams.<br>\n",
    "The second email is very short with weird words. It does not contain enough useful information for us to predict, so it is likely to be classified as a spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the indices of the 1st FP and FN.\n",
    "# Note: spam = 0, ham = 1\n",
    "\n",
    "fn = np.where(np.logical_and(y_test==0, y_pred==1))[0][0]\n",
    "fp = np.where(np.logical_and(y_test==1, y_pred==0))[0][0]\n",
    "\n",
    "inds_test = np.load('data/email_test_inds.npy')\n",
    "fn = inds_test[fn]\n",
    "fp = inds_test[fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp = 24632\n",
      "fn = 8258\n"
     ]
    }
   ],
   "source": [
    "print(\"fp =\", fp)\n",
    "print(\"fn =\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 1st email that is a false positive (classified as spam, but really not) is:\n",
      "------------------------------------------------------------------------------------------\n",
      "Subject: will be on the front page of google in just 48 hours ! guaranteed !\n",
      "your bed and breakfast will be on\n",
      "the front page of google\n",
      "in only 48 hours\n",
      "or your money back ! guaranteed !\n",
      "as partners with\n",
      "google . com and the google network we can offer to place your web site on the\n",
      "front page for your listing !\n",
      "this means that over 80 million real\n",
      "userswho use the google search engineand the google network every\n",
      "day can see your bed and breakfast web site !\n",
      "all for only\n",
      "Â£ 79 . 95 for six months\n",
      "how does it work ?\n",
      "everyone that types in\n",
      "any of these most used phrases below along with your town or city will see your\n",
      "site come up on the first page ! guaranteed !\n",
      "for example\n",
      "if you are a bed and breakfastin manchesterpeople looking for a bb\n",
      "in manchesterwould type in the search boxbed and\n",
      "breakfast inmanchester .\n",
      "below are the 22 most popular phrases that we can offer you .\n",
      "you will have them all !\n",
      "bb in ( your location ) bed and breakfast in ( your location ) bed and breakfasts in ( your location )\n",
      "bandb in\n",
      "( your location )\n",
      "bandbs in\n",
      "( your location ) b and b in ( your location ) bb ( your\n",
      "location ) bbs ( your\n",
      "location ) bed and breakfast ( your\n",
      "location ) bb ( your\n",
      "location ) accommodation in ( your\n",
      "location ) ( your location )\n",
      "accommodation ( your location ) bed and\n",
      "breakfasts ( your location )\n",
      "bb ( your location ) bbs ( your location ) bbs\n",
      "hotels in ( your location )\n",
      "hotel in ( your\n",
      "location ) tourist information ( your\n",
      "location ) holidays in ( your\n",
      "location ) vacations in ( your\n",
      "location )\n",
      "once\n",
      "you have booked our service we will place your town or city where it says\n",
      "( your location ) it will then be activated in only 48\n",
      "hours !\n",
      "a sad\n",
      "fact : many bed and breakfasts spend a\n",
      "small fortune on web site submission and bb directories . but their web\n",
      "sitesare hardly ever seen !\n",
      "with\n",
      "ourunique service your web site will be seen by anyone looking for a bed and\n",
      "breakfast in your area !\n",
      "guaranteed !\n",
      "for obvious reasons we can only offer this toa limited number\n",
      "ofbed and breakfast establishments .\n",
      "to\n",
      "bookiyour siteion\n",
      "thefront page of google today !\n",
      "press\n",
      "here\n",
      "andwe will send to you a link to our webisite\n",
      "or\n",
      "call us on\n",
      "freephone 0800 011 2047\n",
      "outside the uk\n",
      "call 0044 800 011 2047\n",
      "tele lines\n",
      "telecom\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "The 1st email that is a false negative (classified as ham, but really spam) is:\n",
      "------------------------------------------------------------------------------------------\n",
      "Subject: wharton trip january 18 , 2001\n",
      "jeff and vince . . . \" fyi ' ' . . . christie .\n",
      "- - - - - - - - - - - - - - - - - - - - - - forwarded by christie patrick / hou / ect on 12 / 19 / 2000\n",
      "09 : 23 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "melinda mccarty @ enron\n",
      "12 / 19 / 2000 03 : 05 pm\n",
      "to : christie _ patrick @ enron . com\n",
      "cc :\n",
      "subject : wharton trip january 18 , 2001\n",
      "cp -\n",
      "fyi - attached is the memo that i faxed to the parkplace warwick . i copied\n",
      "donna piazze at wharton also .\n",
      "maria\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Use retrieve_emails() to display the first FP and FN.\n",
    "inds = np.array([fp, fn])\n",
    "emails = epp.retrieve_emails(inds)\n",
    "\n",
    "print()\n",
    "print('The 1st email that is a false positive (classified as spam, but really not) is:')\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "print(emails[0])\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "print('The 1st email that is a false negative (classified as ham, but really spam) is:')\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "print(emails[1])\n",
    "print('------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4) Comparison with KNN\n",
    "\n",
    "\n",
    "- Run a similar analysis to what you did with Naive Bayes above. When computing accuracy on the test set, you may want to reduce the size of the test set (e.g. to the first 500 emails in the test set).\n",
    "- Copy-paste your `confusion_matrix` method into `knn.py` so that you can run the same analysis on a KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct and train your KNN classifier\n",
    "classifier = KNN(2)\n",
    "classifier.train(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.898\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the KNN classifier\n",
    "num_test = 500\n",
    "y_pred = classifier.predict(test_data[:num_test], 2)\n",
    "accuracy = classifier.accuracy(y_test[:num_test], y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[253  11]\n",
      " [ 40 196]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.confusion_matrix(y=y_test[:num_test], y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12:** What accuracy did you get on the test set (potentially reduced in size)?\n",
    "\n",
    "**Answer 12:**<br>\n",
    "0.898\n",
    "\n",
    "**Question 13:** How does the confusion matrix compare to that obtained by Naive Bayes?\n",
    "\n",
    "**Answer 13:**<br>\n",
    "False positive errors are still more frequently made by the classifier.<br>\n",
    "A ham is more likely to be classified as spam than the other way around.<br>\n",
    "The false positive rate of the Naive Bayes classifier is 17.0%, and the false positive rate of the KNN classifier is 16.9%.<br>\n",
    "The true positive rate of the Naive Bayes classifier is 94.9%, and the true positive rate of the KNN classifier is 95.8%.<br>\n",
    "It seems that the result obtained by KNN is more accurate.\n",
    "\n",
    "**Question 14:** Briefly describe at least one pro/con of KNN compared to Naive Bayes on this dataset.\n",
    "\n",
    "**Answer 14:**<br>\n",
    "pro of KNN: slightly more accurate--a higher true positive rate and a lower false positive rate.<br>\n",
    "con of KNN: slower than Naive Bayes.<br>\n",
    "\n",
    "**Question 15:** When potentially reducing the size of the test set here, why is it important that we shuffled our train and test set?\n",
    "\n",
    "**Answer 15:**<br>\n",
    "To avoid highly correlated data samples within a small set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions (Section B only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Better text preprocessing\n",
    "\n",
    "- If you look at the top words extracted from the email dataset, many of them are common \"stop words\" (e.g. a, the, to, etc.) that do not carry much meaning when it comes to differentiating between spam vs. non-spam email. Improve your preprocessing pipeline by building your top words without stop words. Analyze performance differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "I made a `remove_stop_words` method in email_preprocessor using NLTK.<br>\n",
    "I added an optional boolean parameter--`remove_sw` whose default value is False--in count_words() and make_feature_vectors() in email_preprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the count of each word in the dataset, ignoring stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq, num_emails = epp.count_words(remove_sw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile a list of the top `num_features` words and their respective counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top 5 words are\n",
      "['enron', 'subject', 'ect', 'com', 'company']\n",
      "The associated counts are\n",
      "[60909, 47811, 35346, 24185, 22959]\n"
     ]
    }
   ],
   "source": [
    "top_words, top_counts = epp.find_top_words(word_freq)\n",
    "print(f\"Your top 5 words are\\n{top_words[:5]}\")\n",
    "print(f\"The associated counts are\\n{top_counts[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that stop words like 'the' 'to' 'and' 'of' 'a' are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a feature vector of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, y = epp.make_feature_vectors(top_words, num_emails, remove_sw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_train_nosw, y_train_nosw, inds_train_nosw, x_test_nosw, y_test_nosw, inds_test_nosw = epp.make_train_test_sets(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/email_train_x_nosw.npy', x_train_nosw)\n",
    "np.save('data/email_train_y_nosw.npy', y_train_nosw)\n",
    "np.save('data/email_train_inds_nosw.npy', inds_train_nosw)\n",
    "np.save('data/email_test_x_nosw.npy', x_test_nosw)\n",
    "np.save('data/email_test_y_nosw.npy', y_test_nosw)\n",
    "np.save('data/email_test_inds_nosw.npy', inds_test_nosw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_nosw = np.load('data/email_train_x_nosw.npy')\n",
    "test_data_nosw = np.load('data/email_test_x_nosw.npy')\n",
    "y_train_nosw = np.load('data/email_train_y_nosw.npy')\n",
    "y_test_nosw = np.load('data/email_test_y_nosw.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nosw = NaiveBayes(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without stop words: 0.9277448071216617\n"
     ]
    }
   ],
   "source": [
    "nb_nosw.train(train_data_nosw, y_train_nosw)\n",
    "y_pred_nosw = nb_nosw.predict(test_data_nosw)\n",
    "accuracy_nosw = nb_nosw.accuracy(y_test_nosw, y_pred_nosw)\n",
    "print(\"Accuracy without stop words:\", accuracy_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the classifier is much higher after the stop words are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix without stop words:\n",
      " [[3298  114]\n",
      " [ 373 2955]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix without stop words:\\n\", nb_nosw.confusion_matrix(y_test_nosw, y_pred_nosw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condusion matrix shows that:<br>\n",
    "False positive errors (ham classified as spam) are still more frequently made by the classifier.<br>\n",
    "The false positive rate becomes lower and is 11.2%.<br>\n",
    "The true positive rate is 96.7%, higher than with stop words.<br>\n",
    "These stats indicate the improved performance of the classifier with stop words removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature size\n",
    "\n",
    "- Explore how the number of selected features for the email dataset influences accuracy and runtime performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added an optional parameter `num_features` with a default value 200 in `make_feature_vectors` of email_preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, y = epp.make_feature_vectors(top_words, num_emails, num_features = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_train_100, y_train_100, inds_train_100, x_test_100, y_test_100, inds_test_100 = epp.make_train_test_sets(features, y)\n",
    "np.save('data/email_train_x_100.npy', x_train_100)\n",
    "np.save('data/email_train_y_100.npy', y_train_100)\n",
    "np.save('data/email_train_inds_100.npy', inds_train_100)\n",
    "np.save('data/email_test_x_100.npy', x_test_100)\n",
    "np.save('data/email_test_y_100.npy', y_test_100)\n",
    "np.save('data/email_test_inds_100.npy', inds_test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_100 = np.load('data/email_train_x_100.npy')\n",
    "test_data_100 = np.load('data/email_test_x_100.npy')\n",
    "y_train_100 = np.load('data/email_train_y_100.npy')\n",
    "y_test_100 = np.load('data/email_test_y_100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_100 = NaiveBayes(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Size = 100\n",
      "Time for training and predicting: 0.15915918350219727\n",
      "Accuracy: 0.886646884272997\n",
      "Confusion Matrix:\n",
      " [[3275  137]\n",
      " [ 627 2701]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "nb_100.train(train_data_100, y_train_100)\n",
    "y_pred_100 = nb_100.predict(test_data_100)\n",
    "end = time.time()\n",
    "print(\"Feature Size = 100\\nTime for training and predicting:\", end - start)\n",
    "accuracy_100 = nb_100.accuracy(y_test_100, y_pred_100)\n",
    "print(\"Accuracy:\", accuracy_100)\n",
    "print(\"Confusion Matrix:\\n\", nb_100.confusion_matrix(y_test_100, y_pred_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.890<br>\n",
    "Confusion Matrix:<br>\n",
    "[[3237  175]<br>\n",
    " [ 565 2763]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, y = epp.make_feature_vectors(top_words, num_emails, num_features = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/qiuyixuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "x_train_300, y_train_300, inds_train_300, x_test_300, y_test_300, inds_test_300 = epp.make_train_test_sets(features, y)\n",
    "np.save('data/email_train_x_300.npy', x_train_300)\n",
    "np.save('data/email_train_y_300.npy', y_train_300)\n",
    "np.save('data/email_train_inds_300.npy', inds_train_300)\n",
    "np.save('data/email_test_x_300.npy', x_test_300)\n",
    "np.save('data/email_test_y_300.npy', y_test_300)\n",
    "np.save('data/email_test_inds_300.npy', inds_test_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_300 = np.load('data/email_train_x_300.npy')\n",
    "test_data_300 = np.load('data/email_test_x_300.npy')\n",
    "y_train_300 = np.load('data/email_train_y_300.npy')\n",
    "y_test_300 = np.load('data/email_test_y_300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_300 = NaiveBayes(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Size = 300\n",
      "Time for training and predicting: 0.21155190467834473\n",
      "Accuracy: 0.937833827893175\n",
      "Confusion Matrix:\n",
      " [[3286  126]\n",
      " [ 293 3035]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "nb_300.train(train_data_300, y_train_300)\n",
    "y_pred_300 = nb_300.predict(test_data_300)\n",
    "end = time.time()\n",
    "print(\"Feature Size = 300\\nTime for training and predicting:\", end - start)\n",
    "accuracy_300 = nb_300.accuracy(y_test_300, y_pred_300)\n",
    "print(\"Accuracy:\", accuracy_300)\n",
    "print(\"Confusion Matrix:\\n\", nb_300.confusion_matrix(y_test_300, y_pred_300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is always a **speed-accuracy trade-off**.<br>\n",
    "\n",
    "It takes more time to train and predict datasets when the feature size is larger.<br>\n",
    "\n",
    "The accuracy gets improved as the feature size increases.<br>\n",
    "\n",
    "##### Compare the confusion matrices:<br>\n",
    "\n",
    "When feature size = 100,<br>\n",
    "the false positive rate is 18.8%, and the true positive rate is 96.0%.<br>\n",
    "\n",
    "When feature size = 200,<br>\n",
    "the false positive rate is 17.0%, and the true positive rate is 94.9%.<br>\n",
    "\n",
    "When feature size = 300,<br>\n",
    "the false positive rate is 8.8%, and the true positive rate is 96.3%.<br>\n",
    "\n",
    "The classifier performs the best when the feature size is 300.<br>\n",
    "However, when the feature size is 100, it has a higher TPR; when the feature size is 300, it has a lower FPR.<br> So they both have some advantages over each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distance metrics\n",
    "- Compare KNN performance with the $L^2$ and $L^1$ distance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added an optional parameter `dist_metrics` in KNN's `predict()` that allows me to choose different distance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 -- Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 performance\n",
      "Accuracy: 0.898\n",
      "Confusion Matrix:\n",
      " [[253  11]\n",
      " [ 40 196]]\n",
      "Time for training and predicting: 208.33208179473877\n"
     ]
    }
   ],
   "source": [
    "knn_l2 = KNN(2)\n",
    "start = time.time()\n",
    "knn_l2.train(train_data, y_train)\n",
    "y_pred_l2 = knn_l2.predict(test_data[:num_test], 2, dist_metrics='L2')\n",
    "end = time.time()\n",
    "accuracy_l2 = knn_l2.accuracy(y_test[:num_test], y_pred_l2)\n",
    "print(\"L2 performance\\nAccuracy:\", accuracy_l2)\n",
    "print(\"Confusion Matrix:\\n\", knn_l2.confusion_matrix(y=y_test[:num_test], y_pred=y_pred_l2))\n",
    "print(\"Time for training and predicting:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 -- Manhattan Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used SciPy's `cityblock` method to compute the Manhattan distances between data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 performance\n",
      "Accuracy: 0.894\n",
      "Confusion Matrix:\n",
      " [[254  10]\n",
      " [ 43 193]]\n",
      "Time for training and predicting: 230.47265696525574\n"
     ]
    }
   ],
   "source": [
    "knn_l1 = KNN(2)\n",
    "start = time.time()\n",
    "knn_l1.train(train_data, y_train)\n",
    "y_pred_l1 = knn_l1.predict(test_data[:num_test], 2, dist_metrics='L1')\n",
    "end = time.time()\n",
    "accuracy_l1 = knn_l1.accuracy(y_test[:num_test], y_pred_l1)\n",
    "print(\"L1 performance\\nAccuracy:\", accuracy_l1)\n",
    "print(\"Confusion Matrix:\\n\", knn_l1.confusion_matrix(y=y_test[:num_test], y_pred=y_pred_l1))\n",
    "print(\"Time for training and predicting:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very similar.<br>\n",
    "Using the L2 distance metric generates a slightly higher accuracy.\n",
    "\n",
    "For both L1 and L2, false positive errors are more frequent.<br>\n",
    "The false positive rate with L1 is 18.2%, and that with L2 if 16.9%.<br>\n",
    "L2 is better at minimizing errors as it predicts fewer false positives.<br>\n",
    "The true positive rate with L1 is 96.2%, and that with L2 if 95.8%.<br>\n",
    "L1 is better at detecting valid solutions/true positives, which makes sense as the L1-norm is diamond-shaped.<br>\n",
    "\n",
    "It took the classifier 230 seconds to train and predict with the L1 distance metrix.<br>\n",
    "With L2, it took 208 seconds.<br>\n",
    "So, in this case, L2 is slightly faster.\n",
    "\n",
    "Since I limited the number of features to 500 which is small, KNN performs slightly better with L2 than with L1.<br>\n",
    "For higher dimensional data, L1 may win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit:\n",
    "\n",
    "Oliver\n",
    "\n",
    "Hannah\n",
    "\n",
    "https://stackoverflow.com/questions/47736531/vectorized-matrix-manhattan-distance-in-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit50fbc1ada7e44b2a861f5b87bf1483ff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
